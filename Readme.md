Here's a complete **`README.md`** file for your project â€” written from the perspective of a **professional content writer** and **Generative AI developer**. It includes:

* Project overview
* Visual architecture
* Features
* Installation & usage instructions
* Example outputs
* Tech stack

---

## ğŸ§  PromptCraft AI â€” Intelligent Prompt Generator & Improver

> A multi-node LangGraph-based agent pipeline that **generates, evaluates, critiques**, and **improves LLM prompts** dynamically using Groq's blazing-fast **LLaMA 3.1 8B** model.
> Built for developers, researchers, and prompt engineers who demand **high-quality prompts**.

---

### ğŸ“¸ Project Architecture

```mermaid
graph TD
    A[User Input: task_description or prompt] --> B{Dispatcher}
    B -->|mode=generate| C[ContextBuilder]
    C --> D[PromptTemplateSelector]
    D --> E[PromptGenerator]
    E --> F[PromptEvaluator]
    F -->|score < 0.7| G[CritiqueNode]
    G --> H[LoopImproverAgent]
    H --> F
    F -->|score â‰¥ 0.7| I[âœ… END]

    B -->|mode=improve| J[PromptImproverDirect]
    J --> I
```

---

## âœ¨ Features

* ğŸ” **Graph-based modular pipeline** using LangGraph
* ğŸš€ Powered by **Groq's LLaMA 3.1 8B-Instant** (ultra-low latency)
* ğŸ§  Supports both:

  * `generate`: full prompt generation with iterative refinement
  * `improve`: direct enhancement of existing prompts using context
* âœ… Automatic prompt **evaluation, scoring, and feedback loop**
* ğŸ› ï¸ Easily extensible (e.g., add scoring history, memory, fine-tuned prompt templates)

---

## ğŸ“¦ Tech Stack

| Tool                 | Role                           |
| -------------------- | ------------------------------ |
| **LangGraph**        | Multi-node graph orchestration |
| **LangChain**        | Prompt templates, chaining     |
| **Groq + LLaMA 3.1** | Lightning-fast inference       |
| **Python**           | Core logic & orchestration     |
| **Dotenv**           | Secure API key management      |

---

## ğŸ§‘â€ğŸ’» How It Works

### ğŸ”¹ 1. Prompt Generation Mode (`mode: generate`)

* Builds context based on task
* Creates a base template
* Generates prompt using LLM
* Evaluates and scores prompt quality
* If score < 0.7, it:

  * Critiques the prompt
  * Refines it using feedback
  * Re-evaluates until threshold met

### ğŸ”¹ 2. Prompt Improvement Mode (`mode: improve`)

* Accepts user-defined prompt + improvement context
* Directly sends to an LLM for enhancement

---

## ğŸ›  Installation

1. **Clone the Repo**

```bash
git clone https://github.com/yourusername/promptcraft-ai.git
cd promptcraft-ai
```

2. **Install Dependencies**

```bash
pip install -r requirements.txt
```

3. **Add Environment Variables**

Create a `.env` file with your Groq API key:

```
GROQ_API_KEY=your-groq-api-key-here
```

---

## ğŸš€ Usage

Run the script:

```bash
python main.py
```

Expected output:

```bash
Running: Full Prompt Generation and Iterative Improvement
--- Evaluator: Score = 0.55, Issue Found = True ---
--- Critique Generated ---
--- Prompt Improved in Loop ---
--- Final Generated Prompt ---
"Explain the theory of relativity to a 10-year-old using a story about two children playing catch on a moving train..."

...

Running: Direct Prompt Improvement with Context
--- Final Improved Prompt ---
"Explain relativity using a train and ball analogy that a child can understand."
```

---

## ğŸ“‚ Directory Structure

```
ğŸ“¦ promptcraft-ai/
 â”£ ğŸ“„ main.py
 â”£ ğŸ“„ README.md
 â”£ ğŸ“„ .env.example
 â”£ ğŸ“„ requirements.txt
```

---

## âœ… Example Inputs & Outputs

### ğŸ”¸ Generate Mode Input

```json
{
  "mode": "generate",
  "task_description": "Create a prompt to explain the theory of relativity to a 10-year-old."
}
```

âœ… **Output**

```json
{
  "prompt": "Explain the theory of relativity using a story involving a train, a ball, and two kids. Use simple language."
}
```

---

### ğŸ”¸ Improve Mode Input

```json
{
  "mode": "improve",
  "prompt": "Explain relativity.",
  "context": "Make the prompt ask for an explanation using a simple analogy involving a train and a ball."
}
```

âœ… **Output**

```json
{
  "improved_prompt": "Explain relativity using a simple train-and-ball analogy suitable for beginners."
}
```

---

## ğŸŒ± Future Enhancements

* ğŸ§  Add memory-aware prompt history using `LangChain Memory`
* ğŸ“Š Dashboard for prompt score tracking
* ğŸ”— API endpoints to use in other apps
* ğŸ§ª Custom fine-tuning of evaluation thresholds

---

## ğŸ™Œ Contributing

Feel free to fork, suggest improvements, or raise issues.
This project is designed to be a plug-and-play module for **any LLM-powered workflow.**

---

## ğŸ“„ License

MIT License Â© 2025 \[Subham Sarkar]

